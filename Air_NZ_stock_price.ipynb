{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br><center> Air New Zealand's weekly stock price prediction based on Google Trend Indexes </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Content](#Table-of-Contents)\n",
    "* [1. Introduction](#1.-Introduction)\n",
    "* [2. Data Acquisition](#2.-Data-Acquisition)\n",
    "    * [2.1 Google Top Trend](#2.1-Google-Top-Trend)\n",
    "    * [2.2 Yahoo Finance](#2.2-Yahoo-Finance)\n",
    "* [3. Data Analysis](#3.-Data-Analysis)\n",
    "    * [3.1 Correlation Analysis](#3.1-Correlation-Analysis)\n",
    "    * [3.2 Linear Analysis](#3.2-Linear-Analysis)\n",
    "        * [Bivariate Analysis](#Bivariate-Analysis)\n",
    "        * [Multivariate Analysis with current stock price](#Multivariate-Analysis-with-current-stock-price)\n",
    "        * [Multivariate Analysis only using Google Trend Indexes](#Multivariate-Analysis-only-using-Google-Trend-Indexes)\n",
    "        * [Multivariate Analysis using sklearn library](#Multivariate-Analysis-using-sklearn-library)\n",
    "        * [Normalization using logarithm](#Normalization-using-logarithm)\n",
    "        * [Linear Regression Models Comparison](#Linear-Regression-Models-Comparison)\n",
    "        * [Normalization using minimum and maximum](#Normalization-using-minimum-and-maximum)\n",
    "    * [3.3 Logistic Regression](#3.3-Logistic-Regression)\n",
    "    * [3.4 KNN](#3.4-KNN)\n",
    "* [4. Conclusion](#4.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report finds the relationship between stock price of Air New Zealand and some keywords related to the company such as 'air new zealand', 'flight' and so on. Also, the report discovers prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import time\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import statsmodels.formula.api as smf\n",
    "import math \n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy import stats\n",
    "from pylab import rcParams\n",
    "import mpld3\n",
    "\n",
    "import tweepy\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "from yahoo_finance import Share\n",
    "from datetime import date\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Google Top Trend\n",
    "This part loads the data using the API. Data is from five years ago to the present and weekly.(source: https://trends.google.co.nz/trends/)\n",
    "\n",
    "**Key Words ** \n",
    "\n",
    "searched worldwide: air new zealand, auckland, wellington\n",
    "\n",
    "searched in New Zealand: air new zealand, flight, travel, airpoints, grab a seat, check in, fiji, dunedin, christchurch, queenstown, nelson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is from https://github.com/GeneralMills/pytrends and is not an Google official API.\n",
    "# The ID is a kind of dummy, not being used one.\n",
    "\n",
    "pytrends = TrendReq('peterhwang105@gmail.com', 'Machine158.222', hl='en-US', tz=360, custom_useragent=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pytrends.build_payload(kw_list=['air new zealand'], cat=0, timeframe='today 5-y', geo='', gprop='')\n",
    "name = pytrends.interest_over_time()\n",
    "name = name.rename(columns={'air new zealand':'airNZ'})\n",
    "pytrends.build_payload(kw_list=['air new zealand'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "namenz = pytrends.interest_over_time()\n",
    "namenz = namenz.rename(columns={'air new zealand':'airNZ_NZ'})\n",
    "pytrends.build_payload(kw_list=['flight'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "flight = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['travel'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "travel = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['airpoints'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "point = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['grab a seat'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "grab = pytrends.interest_over_time()\n",
    "grab = grab.rename(columns={'grab a seat':'grab_a_seat'})\n",
    "pytrends.build_payload(kw_list=['check in'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "check = pytrends.interest_over_time()\n",
    "check = check.rename(columns={'check in':'check_in'})\n",
    "pytrends.build_payload(kw_list=['fiji'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "fiji = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['auckland'], cat=0, timeframe='today 5-y', geo='', gprop='')\n",
    "auckland = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['wellington'], cat=0, timeframe='today 5-y', geo='', gprop='')\n",
    "wellington = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['dunedin'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "dunedin = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['christchurch'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "church = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['queenstown'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "queen = pytrends.interest_over_time()\n",
    "pytrends.build_payload(kw_list=['nelson'], cat=0, timeframe='today 5-y', geo='NZ', gprop='')\n",
    "nelson = pytrends.interest_over_time()\n",
    "airGgl = pd.concat([name, namenz, flight, travel, point, grab, check, fiji, auckland, wellington, dunedin, church, queen, nelson], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airNZ</th>\n",
       "      <th>airNZ_NZ</th>\n",
       "      <th>flight</th>\n",
       "      <th>travel</th>\n",
       "      <th>airpoints</th>\n",
       "      <th>grab_a_seat</th>\n",
       "      <th>check_in</th>\n",
       "      <th>fiji</th>\n",
       "      <th>auckland</th>\n",
       "      <th>wellington</th>\n",
       "      <th>dunedin</th>\n",
       "      <th>christchurch</th>\n",
       "      <th>queenstown</th>\n",
       "      <th>nelson</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-05</th>\n",
       "      <td>77.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-12</th>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-19</th>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-26</th>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-02</th>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            airNZ  airNZ_NZ  flight  travel  airpoints  grab_a_seat  check_in  \\\n",
       "date                                                                            \n",
       "2012-08-05   77.0      74.0    45.0    88.0       49.0         85.0      46.0   \n",
       "2012-08-12   78.0      78.0    47.0    89.0       43.0         79.0      39.0   \n",
       "2012-08-19   75.0      71.0    46.0    84.0       45.0         71.0      54.0   \n",
       "2012-08-26   75.0      71.0    52.0    79.0       40.0         83.0      56.0   \n",
       "2012-09-02   76.0      77.0    54.0    86.0       56.0         76.0      44.0   \n",
       "\n",
       "            fiji  auckland  wellington  dunedin  christchurch  queenstown  \\\n",
       "date                                                                        \n",
       "2012-08-05  43.0      72.0        57.0     55.0          54.0        39.0   \n",
       "2012-08-12  52.0      75.0        58.0     57.0          57.0        44.0   \n",
       "2012-08-19  45.0      75.0        59.0     56.0          55.0        45.0   \n",
       "2012-08-26  47.0      71.0        58.0     55.0          55.0        40.0   \n",
       "2012-09-02  44.0      74.0        58.0     57.0          55.0        39.0   \n",
       "\n",
       "            nelson  \n",
       "date                \n",
       "2012-08-05    40.0  \n",
       "2012-08-12    43.0  \n",
       "2012-08-19    40.0  \n",
       "2012-08-26    41.0  \n",
       "2012-09-02    43.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airGgl = airGgl.astype(float)\n",
    "airGgl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gain today and 5 years ago date\n",
    "today=dt.date.today()\n",
    "fiveYearAgo = today.replace(year = today.year -5)\n",
    "#coverting datetime into string\n",
    "today = today.strftime('%Y-%m-%d')\n",
    "fiveYearAgo = fiveYearAgo.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function define\n",
    "# This function is to get average adjusted value, next week average value, volume of a week and the date(First date of the week which is Sunday)\n",
    "def avrVolValNvalNDate(df):\n",
    "    pre = 4\n",
    "    aVol = []\n",
    "    date = []\n",
    "    aAdj = []\n",
    "    nAdj = []\n",
    "    vsum = 0\n",
    "    asum = 0\n",
    "    vcount = 0\n",
    "    acount = 0\n",
    "    nAV = np.nan\n",
    "    for index, adj, vol in zip(df.index, df['Adj_Close'],df['Volume']):\n",
    "        if(pre<index.weekday()):\n",
    "            if(vcount==0):\n",
    "                aVol.append(0)\n",
    "            else:\n",
    "                aVol.append((vsum/vcount))\n",
    "            aAdj.append((asum/acount))\n",
    "            nAdj.append(nAV)\n",
    "            nAV = asum/acount\n",
    "            if(index.weekday()==4):\n",
    "                date.append(index + datetime.timedelta(days=2))\n",
    "            elif(index.weekday()==3):\n",
    "                date.append(index + datetime.timedelta(days=3))\n",
    "            elif(index.weekday()==2):\n",
    "                date.append(index + datetime.timedelta(days=4))\n",
    "            elif(index.weekday()==1):\n",
    "                date.append(index + datetime.timedelta(days=5))\n",
    "            elif(index.weekday()==0):\n",
    "                date.append(index + datetime.timedelta(days=6))\n",
    "            pre = index.weekday()\n",
    "            vsum = vol\n",
    "            asum = adj\n",
    "            vcount = 1\n",
    "            if(vol==0):\n",
    "                vcount = 0\n",
    "            acount = 1\n",
    "        else:\n",
    "            vsum = vsum + vol\n",
    "            asum = asum + adj\n",
    "            acount = acount +1\n",
    "            vcount = vcount +1\n",
    "            if(vol==0):\n",
    "                vcount = vcount -1 #volume 0 means that the market did not open on that day\n",
    "            pre = index.weekday()\n",
    "    return aVol, aAdj, nAdj, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function adds a column which indicates whether the stock price increased or decreased\n",
    "# 0 : same or decreased\n",
    "# 1 : increased\n",
    "def checkINC(df):\n",
    "    temp = []\n",
    "    for nV, cV in zip(df['Nxt_Value'],df['Value']):\n",
    "        if((nV-cV) > 0.0):\n",
    "            temp.append(1)\n",
    "        elif((nV-cV) <= 0.0):\n",
    "            temp.append(0)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is for gaining the change rate of index\n",
    "def rate(df):\n",
    "    d = pd.DataFrame()\n",
    "    for col in df.columns[:]:\n",
    "        pre = -1.0\n",
    "        temp = []\n",
    "        for row in df[col]:\n",
    "            if(pre == -1.0):\n",
    "                temp.append(np.nan)\n",
    "                pre = float(row)\n",
    "            else :\n",
    "                row = float(row)\n",
    "                r = ((row - pre)/pre)\n",
    "                temp.append(r)\n",
    "                pre = row\n",
    "        d['r'+col] = temp\n",
    "    d.index = df.index\n",
    "    d = d.dropna(axis=0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yahoo_finance import Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_s = Share('AIR.NZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "YQLResponseMalformedError",
     "evalue": "Response malformed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mYQLResponseMalformedError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6d7f9b9237a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mair_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_historical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2016-01-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2017-01-01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/PeterHwang/anaconda/lib/python2.7/site-packages/yahoo_finance/__init__.pyc\u001b[0m in \u001b[0;36mget_historical\u001b[0;34m(self, start_date, end_date)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'historicaldata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartDate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendDate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PeterHwang/anaconda/lib/python2.7/site-packages/yahoo_finance/__init__.pyc\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mYQLQueryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mYQLResponseMalformedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_error_in_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mYQLResponseMalformedError\u001b[0m: Response malformed."
     ]
    }
   ],
   "source": [
    "air_s.get_historical(\"2016-01-01\", \"2017-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_history = air_s.get_historical(fiveYearAgo, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_history = pd.DataFrame(air_history)\n",
    "air_history = air_history.set_index('Date')\n",
    "air_history.index = pd.to_datetime(air_history.index)\n",
    "air_history['Volume'] = pd.to_numeric(air_history['Volume'])\n",
    "air_history['Adj_Close'] = pd.to_numeric(air_history['Adj_Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vol_temp = []\n",
    "adj_temp = []\n",
    "date_temp = []\n",
    "nAdj_temp = []\n",
    "vol_temp, adj_temp, nAdj_temp, date_temp = avrVolValNvalNDate(air_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp = pd.DataFrame({'Volume':vol_temp,'Value':adj_temp, 'Nxt_Value': nAdj_temp}, index=date_temp)\n",
    "air = pd.concat([temp, airGgl], axis=1, join_axes=[airGgl.index])\n",
    "air = air.dropna(axis = 0)\n",
    "\n",
    "airNZ_rate = rate(airGgl)\n",
    "airNZ_rate = pd.concat([temp, airNZ_rate], axis=1, join_axes=[airNZ_rate.index])\n",
    "airNZ_rate = airNZ_rate.dropna(axis = 0)\n",
    "\n",
    "air['Check_INC'] = checkINC(air)\n",
    "cols = air.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "air = air[cols]\n",
    "\n",
    "# to predict using the change rate of Google Trend Indexes\n",
    "airNZ_rate['Check_INC'] = checkINC(airNZ_rate)\n",
    "cols = airNZ_rate.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "airNZ_rate = airNZ_rate[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google Trend data and Stock data are kept changing, so the research uses the data on 21/4/2017 store into csv files. The main purpose is to remove outliers. Fron now on, the report finds several models based on the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#air.to_csv('air.csv')\n",
    "air = pd.read_csv('air.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This table is based on Google Trend Indexes\n",
    "air.corr().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.title('Pearson Correlation of Air New Zealand stock price and volume and Google search', y=1.05, size=15)\n",
    "sns.heatmap(air.astype(float).corr(),linewidths=0.1,vmax=1.0,  fmt='.2f', square=True, cmap='magma', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This table is to analyse based on the change rate of Google Trend Indexes\n",
    "airNZ_rate.corr().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.title('Pearson Correlation of Air New Zealand stock price and volume and Google search', y=1.05, size=15)\n",
    "sns.heatmap(airNZ_rate.astype(float).corr(),linewidths=0.1,vmax=1.0,  fmt='.2f', square=True, cmap='magma', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change rate of Google Trend Index seems not to have any relationship with stock price. So, the research only focuses on just Google Trend Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrmat = air.corr()\n",
    "k = 18 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'Nxt_Value')['Nxt_Value'].index\n",
    "cm = np.corrcoef(air[cols].values.T)\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(14,14))\n",
    "hm = sns.heatmap(cm, cbar=True, linewidths=0.1,vmax=1.0,annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use only variations which are correlation > |0.5|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COLUMNS: variations are correlation > |0.5|\n",
    "COLUMNS = ['Nxt_Value', 'Value', 'check_in', 'wellington', 'queenstown', 'dunedin','airpoints', 'nelson', 'airNZ', 'grab_a_seat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(air[COLUMNS], size = 2)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Linear Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'Value'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'check_in'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'wellington'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are two points when wellington = 77.0 \n",
    "# so remove the point using Volume\n",
    "# make sure 276640.0 Volume is only one value.\n",
    "air.Volume.value_counts()[276640.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)\n",
    "air = air.drop(air[air[var] == 93.0].index)\n",
    "air = air.drop(air[air[var] == 92.0].index)\n",
    "air = air.drop(air[air[var] == 91.0].index)\n",
    "air = air.drop(air[air['Volume'] == 276640.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'queenstown'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are two points when queenstown = 80.0 \n",
    "# so remove the point using Volume\n",
    "# make sure 134700.0 Volume is only one value.\n",
    "air.Volume.value_counts()[134700.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)\n",
    "air = air.drop(air[air[var] == 93.0].index)\n",
    "air = air.drop(air[air[var] == 92.0].index)\n",
    "air = air.drop(air[air[var] == 86.0].index)\n",
    "air = air.drop(air[air['Volume'] == 134700.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'dunedin'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'airpoints'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)\n",
    "air = air.drop(air[air[var] == 85.0].index)\n",
    "air = air.drop(air[air[var] == 82.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'nelson'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)\n",
    "air = air.drop(air[air[var] == 75.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'airNZ'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = 'grab_a_seat'\n",
    "data = pd.concat([air['Nxt_Value'], air[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='Nxt_Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points which grab a seat > 90 are obviously outliers. So get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.sort_values(by = var, ascending = False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air = air.drop(air[air[var] == 100.0].index)\n",
    "air = air.drop(air[air[var] == 94.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrmat = air.corr()\n",
    "k = 18 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'Nxt_Value')['Nxt_Value'].index\n",
    "cm = np.corrcoef(air[cols].values.T)\n",
    "sns.set(font_scale=1)\n",
    "plt.figure(figsize=(14,14))\n",
    "hm = sns.heatmap(cm, cbar=True, linewidths=0.1,vmax=1.0,annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(air[COLUMNS], size = 2)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After remove outliers, some correlation values have been increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the x-axis values that are in range for the 'Value' values\n",
    "x = pd.DataFrame({'Value': np.linspace(air.Value.min(), air.Value.max(), len(air.Value))})\n",
    "\n",
    "#generate the model which uses the stock price to predict the next stock price - the ols() return the generated model\n",
    "mod = smf.ols(formula='Nxt_Value ~ 1 + Value', data=air).fit()\n",
    "\n",
    "#plot the actual data\n",
    "plt.scatter(air.Value, air.Nxt_Value, s=20, alpha=0.6)\n",
    "plt.xlabel('Current Value'); plt.ylabel('Next Value')\n",
    "\n",
    "#render the regression line by predicting the ys using the generated model from above\n",
    "plt.plot(x.Value, mod.predict(x), 'b-', label='Linear $R^2$=%.2f' % mod.rsquared, alpha=0.9)\n",
    "\n",
    "#give the figure a meaningful legend\n",
    "plt.legend(loc='upper left', framealpha=0.5, prop={'size':'small'})\n",
    "plt.title(\"Predicting the next week stock prices based on current week stock value\")\n",
    "\n",
    "#display the model statistics describing the goodness of fit\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gapPredicNReal(NxtV, Val):\n",
    "    temp = []\n",
    "    pred = []\n",
    "    for nxt, crr in zip(NxtV, Val):\n",
    "        est = crr*mod.params[1] +mod.params[0]\n",
    "        gap = est - nxt\n",
    "        pred.append(est)\n",
    "        temp.append(gap)\n",
    "    return temp, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gapSngl, predicBi = gapPredicNReal(air['Nxt_Value'], air['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = air.index\n",
    "y = gapSngl\n",
    "x = pd.to_datetime(x)\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    name = 'Below',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "layout = dict(title = 'Difference between forecasted and actual stock price',\n",
    "              yaxis = dict(zeroline = True),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snglErrors = []\n",
    "print metrics.mean_absolute_error(air['Nxt_Value'], predicBi)\n",
    "snglErrors.append(metrics.mean_absolute_error(air['Nxt_Value'], predicBi))\n",
    "print metrics.mean_squared_error(air['Nxt_Value'], predicBi)\n",
    "snglErrors.append(metrics.mean_squared_error(air['Nxt_Value'], predicBi))\n",
    "print np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predicBi))\n",
    "snglErrors.append(np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predicBi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis with current stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_linear = smf.ols(formula='Nxt_Value ~ 1 + Value + check_in + wellington + queenstown + dunedin + airpoints + nelson + airNZ + grab_a_seat', data=air[COLUMNS]).fit()\n",
    "print multi_linear.params[0:10]\n",
    "print 'R-Squared: ', multi_linear.rsquared\n",
    "multi_linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gapPredMultiVal(df): \n",
    "    temp = []\n",
    "    pred = []\n",
    "    for row in range(0,len(df)):\n",
    "        estimate = 0.0\n",
    "        for col in df.columns[1:]:\n",
    "            estimate = estimate + (multi_linear.params[col])*df.ix[row,col]\n",
    "        estimate = estimate +(multi_linear.params['Intercept'])\n",
    "        gap = estimate - df.ix[row,'Nxt_Value']\n",
    "        pred.append(estimate)\n",
    "        temp.append(gap)\n",
    "    return temp, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gapMulti, predicMlt = gapPredMultiVal(air[COLUMNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(air.index)\n",
    "y = gapMulti\n",
    "x = pd.to_datetime(x)\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    name = 'Below',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "layout = dict(title = 'Difference between forecasted and actual stock price',\n",
    "              yaxis = dict(zeroline = True),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiErrors = []\n",
    "print metrics.mean_absolute_error(air['Nxt_Value'], predicMlt)\n",
    "multiErrors.append(metrics.mean_absolute_error(air['Nxt_Value'], predicMlt))\n",
    "print metrics.mean_squared_error(air['Nxt_Value'], predicMlt)\n",
    "multiErrors.append(metrics.mean_squared_error(air['Nxt_Value'], predicMlt))\n",
    "print np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predicMlt))\n",
    "multiErrors.append(np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predicMlt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis only using Google Trend Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_linear = smf.ols(formula='Nxt_Value ~ 1 + check_in + wellington + queenstown + dunedin + airpoints + nelson + airNZ + grab_a_seat', data=air[COLUMNS]).fit()\n",
    "print multi_linear.params[0:10]\n",
    "print 'R-Squared: ', multi_linear.rsquared\n",
    "multi_linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempCols = ['Nxt_Value','check_in','wellington','queenstown','dunedin','airpoints','nelson','airNZ','grab_a_seat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gapOnlyGTrend, predicOnlyGg = gapPredMultiVal(air[tempCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(air.index)\n",
    "y = gapOnlyGTrend\n",
    "x = pd.to_datetime(x)\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    name = 'Below',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "layout = dict(title = 'Difference between forecasted and actual stock price',\n",
    "              yaxis = dict(zeroline = True),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiGgErrors = []\n",
    "print metrics.mean_absolute_error(air['Nxt_Value'], predicOnlyGg)\n",
    "multiGgErrors.append(metrics.mean_absolute_error(air['Nxt_Value'], predicOnlyGg))\n",
    "print metrics.mean_squared_error(air['Nxt_Value'], predicOnlyGg)\n",
    "multiGgErrors.append(metrics.mean_squared_error(air['Nxt_Value'], predicOnlyGg))\n",
    "print np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predicOnlyGg))\n",
    "multiGgErrors.append(np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predicOnlyGg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Analysis using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air[COLUMNS[1:]]\n",
    "y = air['Nxt_Value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(lm.coef_, X.columns, columns=['Coeff'])\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.to_datetime(y_test.index)\n",
    "trace1 = go.Scatter(\n",
    "    x = d,\n",
    "    y = (y_test-predictions),\n",
    "    name = 'Below',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "layout = dict(title = 'Difference between forecasted and actual stock price',\n",
    "              yaxis = dict(zeroline = True),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % (y_test-predictions).skew())\n",
    "sns.distplot((y_test-predictions), fit=norm)\n",
    "plt.xlabel('y_test-predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearnErrors = []\n",
    "print metrics.mean_absolute_error(y_test, predictions)\n",
    "sklearnErrors.append(metrics.mean_absolute_error(y_test, predictions))\n",
    "print metrics.mean_squared_error(y_test, predictions)\n",
    "sklearnErrors.append(metrics.mean_squared_error(y_test, predictions))\n",
    "print np.sqrt(metrics.mean_squared_error(y_test, predictions))\n",
    "sklearnErrors.append(np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization using logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#histogram and normal probability plot\n",
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % air['Nxt_Value'].skew())\n",
    "print(\"Kurtosis: %f\" % air['Nxt_Value'].kurt())\n",
    "sns.distplot(air['Nxt_Value'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(air['Nxt_Value'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#applying log transformation\n",
    "air_log = pd.DataFrame()\n",
    "for col in air.columns[1:]:\n",
    "    air_log.loc[:,col] = np.log(air.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % air_log['Nxt_Value'].skew())\n",
    "print(\"Kurtosis: %f\" % air_log['Nxt_Value'].kurt())\n",
    "sns.distplot(air_log['Nxt_Value'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(air_log['Nxt_Value'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(air_log[COLUMNS], size = 2)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data has changed to more normal. But, the absolute skewness value of the next stock prices as a predictor has been increased. So, this research did not use logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Original correlation:',(air[air.columns[:]].corr()['Volume']['Nxt_Value'])\n",
    "print 'After transformed:',(air_log[air_log.columns[:]].corr()['Volume']['Nxt_Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transformed, the research found that the correlationship between 'Volume' and 'Nxt_Value' has significantly increased from -0.000116629340474 to 0.487494271303. But it is still less than 0.5 so we do not use 'Volume'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air_log[COLUMNS[1:]]\n",
    "y = air_log['Nxt_Value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(lm.coef_, X.columns, columns=['Coeff'])\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.exp(y_test), np.exp(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.to_datetime(y_test.index)\n",
    "trace1 = go.Scatter(\n",
    "    x = d,\n",
    "    y = (np.exp(y_test)-np.exp(predictions)),\n",
    "    name = 'Below',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "layout = dict(title = 'Difference between forecasted and actual stock price',\n",
    "              yaxis = dict(zeroline = True),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logErrors = []\n",
    "print metrics.mean_absolute_error(np.exp(y_test), np.exp(predictions))\n",
    "logErrors.append(metrics.mean_absolute_error(np.exp(y_test), np.exp(predictions)))\n",
    "print metrics.mean_squared_error(np.exp(y_test), np.exp(predictions))\n",
    "logErrors.append(metrics.mean_squared_error(np.exp(y_test), np.exp(predictions)))\n",
    "print np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(predictions)))\n",
    "logErrors.append(np.sqrt(metrics.mean_squared_error(np.exp(y_test), np.exp(predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Bivariate:                        ', snglErrors\n",
    "print 'Multi-variate with stock:         ', multiErrors\n",
    "print 'Multi-variate only Google Indexes:', multiGgErrors\n",
    "print 'Multi-variate using sklearn lib:  ', sklearnErrors\n",
    "print 'Multi-variate after log transform:', logErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amongst 4 models, the model using sklearn library has the lowest error values. This model may be the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization using minimum and maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler().fit(air[COLUMNS])\n",
    "air_minmax = minmax_scale.transform(air[COLUMNS])\n",
    "air_minmax = pd.DataFrame(air_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % air_minmax[0].skew())\n",
    "print(\"Kurtosis: %f\" % air_minmax[0].kurt())\n",
    "sns.distplot(air_minmax[0], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(air_minmax[0], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization using minimum and maximum seems not good since the skewness has not changed significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model predict whether the next week's average stock price will be increased or decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air[COLUMNS[1:]]\n",
    "y = air['Check_INC']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so bad. This model has a probability of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section predicts that the next week average stock value will be increased or decreased using KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(air[COLUMNS[1:]])\n",
    "scaled_features = scaler.transform(air[COLUMNS[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_feat = pd.DataFrame(scaled_features, columns=COLUMNS[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air_feat\n",
    "y = air['Check_INC']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(range(1,40),error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize = 8)\n",
    "plt.title('Error Rate vs K value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This KNN model seems worse than logistic regression model. It has a probabilty of 67%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although stock and google index have relatively high correlation, it is only a probabilty of 75% to predict that the stock would go up or down. But, as linear models showed, Google Trend Index may be used as an auxiliary measure to predict stock price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air.drop('Check_INC', axis=1)\n",
    "y = air['Check_INC']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (confusion_matrix(y_test, predictions))\n",
    "print '\\n'\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air.drop(['Check_INC','Nxt_Value'], axis=1)\n",
    "y = air['Nxt_Value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBest = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features='sqrt',\n",
    "                                               min_samples_leaf=15, min_samples_split=10, loss='huber').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logToReal(array):\n",
    "    temp = []\n",
    "    for log_price in array:\n",
    "        temp.append(np.exp(log_price))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictGB = GBest.fit(X, y).predict(X)\n",
    "#predictGB_Val = logToReal(predictGB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print metrics.mean_absolute_error(air['Nxt_Value'], predictGB)\n",
    "print metrics.mean_squared_error(air['Nxt_Value'], predictGB)\n",
    "print np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predictGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace0 = go.Bar(x=air.index,y=air['Nxt_Value'], name='actual')\n",
    "trace1 = go.Bar(x=air.index, y=predictGB, name='predicted')\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='angled-text-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction without current stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = air.drop(['Check_INC','Nxt_Value','Value' ], axis=1)\n",
    "y = air['Nxt_Value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBest = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features='sqrt',\n",
    "                                               min_samples_leaf=15, min_samples_split=10, loss='huber').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictGB2 = GBest.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print metrics.mean_absolute_error(air['Nxt_Value'], predictGB2)\n",
    "print metrics.mean_squared_error(air['Nxt_Value'], predictGB2)\n",
    "print np.sqrt(metrics.mean_squared_error(air['Nxt_Value'], predictGB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace0 = go.Bar(x=air.index,y=air['Nxt_Value'], name='actual')\n",
    "trace1 = go.Bar(x=air.index, y=predictGB2, name='predicted')\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    barmode='group',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='angled-text-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
